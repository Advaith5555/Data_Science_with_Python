{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e612f9b3-ae59-42dc-8024-c77ffa00c580",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8ee95-0f91-42c9-a6dc-383577474bab",
   "metadata": {},
   "source": [
    "#### what is Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217c0a8-31a8-4ac1-a477-002eae26ede4",
   "metadata": {},
   "source": [
    "- Imagine how your brain works \n",
    "- Your brain has neurons, which pass signals to each other\n",
    "- neural networks are inspired by this\n",
    "- A perceptron is like a single brain cell (neuron) in a computer\n",
    "- multiple perceptrons connected together => neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e7585-8f5a-4f2f-ba3a-5c7ddc6144ca",
   "metadata": {},
   "source": [
    "#### What is Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87c94e-9425-4e48-90ad-9411f8ee0dbc",
   "metadata": {},
   "source": [
    "- Think of a perceptron as\n",
    "- It takes input (features)\n",
    "- applies weights to the input\n",
    "- adds them together + Bias\n",
    "- passes the result through an activation function to make decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe17a93-8de5-43b5-9636-6164504ce183",
   "metadata": {},
   "source": [
    "### Formula :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2c680-34b3-4a61-91ca-068ee16043de",
   "metadata": {},
   "source": [
    "- Output = Activation ((Input1 * Weight1) + (Input2 * Weight2) + ... + Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30b34b-9fa9-4a24-ab45-1fb0255dfbf9",
   "metadata": {},
   "source": [
    "#### What is Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f8a82-0bb8-4864-927a-b770bfa5a912",
   "metadata": {},
   "source": [
    "- Activation decides :\n",
    "- Should the Neuron fire (Activate) or not\n",
    "- introduces non-linearity, helps model complex problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6dbbc9-1f41-4db4-ad62-eb1d70570fe7",
   "metadata": {},
   "source": [
    "| Name | Purpose | Range |\n",
    "|------|---------|-------|\n",
    "| Sigmoid | Binary outputs (0 to 1) | 0 to 1 |\n",
    "| Tanh | Outputs between -1 to 1 | -1 to 1 |\n",
    "| ReLU | keeps positives, removes negatives | 0 to â™¾  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1b2b6-d449-41e3-a0a3-52dbd35ca756",
   "metadata": {},
   "source": [
    "#### Perceptron with Python example\n",
    "- We will build a simple perceptron to solve a logical OR problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4261b9-84ea-4643-a16b-00572015ca73",
   "metadata": {},
   "source": [
    "| Input 1 | Input 2 | Output (OR) |\n",
    "|---------|---------|-------------|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2d9d2-ad85-4444-8722-08209739312d",
   "metadata": {},
   "source": [
    "### Real World Analogy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5600ff4-4a04-4b3b-9743-f0e8d251d73f",
   "metadata": {},
   "source": [
    "- Imagine learning to throw a ball into a basket\n",
    "- You try, miss, adjust (like updating weights)\n",
    "- You keep practicing until you consistently hit the target\n",
    "- Perceptron learns similarly and adjusts itself based on errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "620e0673-2dc8-462d-968d-16d79998e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0ffc1d-6f8e-4e66-a189-197b54d40953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55dea21-3e52-44e7-a838-09a20add18a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0,1,1,1])\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bbb0829-937e-4331-9e64-3d221de15435",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(2) \n",
    "bias =np.random.rand(1)\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# derivative for learning\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d7a53-8c12-4215-8efc-c0005bf92f30",
   "metadata": {},
   "source": [
    "#### Training parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e51057-b038-4456-936f-2890ad96ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000 # iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779de4a-2af0-40d2-991f-e0a5a76cb17a",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be8d69e-91d0-4b6e-99c5-2324a62c1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : [6.807613   6.81330676]\n",
      "Bias : [-2.92676327]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (epochs):\n",
    "    for i in range (len(X)):\n",
    "\n",
    "        # weighted sum\n",
    "        z = np.dot(X[i], weights) + bias\n",
    "        \n",
    "        # Apply Activation\n",
    "        output = sigmoid(z)\n",
    "\n",
    "        # error\n",
    "        error = y[i] - output\n",
    "\n",
    "        # Update rule (gradient descent)\n",
    "        weights += learning_rate * error * X[i]\n",
    "\n",
    "        bias += learning_rate * error \n",
    "\n",
    "print(f\"weights : {weights}\")\n",
    "print(f\"Bias : {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8ede1e-a3d0-4553-9d5f-4b4a6862704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " testing the OR Gate perceptron\n",
      "Input: [0 0] | Predicted: 0 | Actual: 0\n",
      "Input: [0 1] | Predicted: 1 | Actual: 1\n",
      "Input: [1 0] | Predicted: 1 | Actual: 1\n",
      "Input: [1 1] | Predicted: 1 | Actual: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smita\\AppData\\Local\\Temp\\ipykernel_8892\\3053526283.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"Input: {X[i]} | Predicted: {round(float(output))} | Actual: {y[i]}\" )\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n testing the OR Gate perceptron\")\n",
    "\n",
    "for i in range (len(X)):\n",
    "    z = np.dot(X[i], weights) + bias\n",
    "\n",
    "    output = sigmoid(z)\n",
    "\n",
    "    print(f\"Input: {X[i]} | Predicted: {round(float(output))} | Actual: {y[i]}\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad7850-f122-465e-b831-88e15e4e6447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
